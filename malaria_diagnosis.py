# -*- coding: utf-8 -*-
"""Malaria_diagnosis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RIr0sIfNsrzVaA7-BEHauuA_lrXxqIa3

<h2><u>Malaria Diagnosis</h2></u>
<h3><u><b>Main task of the model</b></u></h3>
<P>
The model aims at detecting the plasmodium parasite form the microscopic images of blood cells in the sample to detect malaria
</p>
"""

!pip install tensorflow
!pip install tensorflow-probability
!pip install tf_keras
!pip install albumentations

!pip install wandb

!pip install tensorflow-estimator # Install tensorflow-estimator

#importing the packages
import tensorflow as tf
import numpy as np
from matplotlib import pyplot as plt
import albumentations as A
# from tensorflow_estimator.python.estimator.api._v1 import estimator
import tensorflow_probability as tfp
from tensorflow.keras.models import Model
import tensorflow_datasets as tfds
import pandas as pd
from tensorflow.keras.layers import Normalization, Conv2D, MaxPool2D, Dense, Flatten, InputLayer, BatchNormalization, Input, Layer, Dropout, RandomFlip,RandomRotation,RandomContrast, RandomBrightness, Resizing,Rescaling
from tensorflow.keras.losses import BinaryCrossentropy, Loss
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import BinaryAccuracy, FalseNegatives, FalsePositives,TruePositives, TrueNegatives, Precision, Recall, AUC
from tensorflow.keras.callbacks import Callback, CSVLogger, EarlyStopping, LearningRateScheduler, ModelCheckpoint
from tensorflow.keras.regularizers import L1,L2 #importing regularizers
from tensorboard.plugins.hparams import api as hp
import io
import sklearn
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc
import seaborn as sns
import datetime
import wandb
from wandb.keras import WandbCallback
print("All packages imported")

ds,ds_info = tfds.load('malaria', with_info = True,
                       as_supervised = True,
                       shuffle_files = True,
                       split = ['train'])

type(ds)

for data in ds[0].take(1):
  print(data)
  print(type(data))

#defining the split constants -
  TRAIN_RATIO = 0.6
  TEST_RATIO = 0.2
  VAL_RATIO = 0.2

def split(data,TRAIN_RATIO,TEST_RATIO,VAL_RATIO):
  dataset_size = len(data)
  train_data = data.take(int(dataset_size*TRAIN_RATIO))
  test_data = data.skip(len(train_data)).take(int(dataset_size*TEST_RATIO))
  val_data = data.skip(len(test_data)).take(int(dataset_size*VAL_RATIO))

  return train_data,test_data,val_data

train,test,val = split(ds[0],TRAIN_RATIO,TEST_RATIO,VAL_RATIO)

test

for i,(image,label) in enumerate(train.take(16)):
  ax = plt.subplot(4,4,i+1)
  plt.imshow(image)
  plt.title(ds_info.features['label'].int2str(label))
  plt.axis('off')

#here the preprocessing begins.........
IMG_SIZE = 224
def resize_rescale(image,label):
  #checking 3 dimensions(W,H,C) before actually resizing the image0
  # image = tf.expand_dims(image,axis = -1) if image.ndim ==2 else image
  image = tf.image.resize(image, [IMG_SIZE,IMG_SIZE])
  return image, label

import cv2

LAMBDA = tfp.distributions.Beta(0.2,0.2).sample(1)[0]

def box(LAMBDA):

  r_x = tf.cast(tfp.distributions.Uniform(0,IMG_SIZE).sample(1)[0], dtype = tf.int32)
  r_y = tf.cast(tfp.distributions.Uniform(0,IMG_SIZE).sample(1)[0], dtype = tf.int32)
  #for obtaining the image_size =
  r_w = tf.cast(IMG_SIZE*tf.math.sqrt(1-LAMBDA),dtype = tf.int32)
  r_h = tf.cast(IMG_SIZE*tf.math.sqrt(1-LAMBDA),dtype = tf.int32)

  b_r_x = tf.clip_by_value(r_x+r_w//2,0,IMG_SIZE) #to avoid getting off the image
  b_r_y = tf.clip_by_value(r_y+r_h//2,0,IMG_SIZE) #to avoid getting off the image

  #specifying the new height and width -specific to the cut -
  r_w = b_r_x-r_x

  if r_w==0:
    r_w = 1

  r_h = b_r_y-r_y

  if r_h==0:
    r_h= 1

  return r_x,r_y,r_w,r_h

class rotate_90(Layer):
  def __init__(self):
    super().__init__()

  @tf.function
  def call(self,image):
    return tf.image.rot90(image)

#defining the augmentation method to integrate with our pipeline -
@tf.function
def augment(image, label):
  image,label = resize_rescale(image,label)

  image = tf.image.rot90(image, k=tf.random.uniform(shape = [], minval = 0, maxval = 2, dtype = tf.int32))
  image = tf.image.random_contrast(image,0.3,0.7)
  image = tf.image.adjust_brightness(image,0.4)
  image = tf.image.adjust_hue(image,0.4)
  image = tf.image.flip_left_right(image)

  return image, label

IMG_SIZE = 224

#creating an augmentation layer, to integrate that with the main model -
augmentation_layer = tf.keras.Sequential([
  Resizing(IMG_SIZE,IMG_SIZE),
  Rescaling(1/255),
  RandomRotation(0.2),
  RandomContrast(0.6),
  RandomBrightness(0.4),
  RandomFlip('horizontal_and_vertical')
])

resize_rescaling_layer = tf.keras.Sequential([
    Resizing(IMG_SIZE,IMG_SIZE),
    Rescaling(1/255)
])

@tf.function
def augment_layers(image):
  return augmentation_layer(image,training = True) # the layer wil have trainable parameters.

tf.config.run_functions_eagerly(True)

"""<h2><b>Mix-Up Data Augmentation</b></h2>

"""

import cv2

# factor = factor.sample(1)[#defining the traiing datasets to be integrated into mix-up
train_dataset_1 = train.shuffle(buffer_size = 8, reshuffle_each_iteration=True).map(resize_rescale)
train_dataset_2 = train.shuffle(buffer_size = 8, reshuffle_each_iteration =True).map(resize_rescale)
mixed_dataset = tf.data.Dataset.zip((train_dataset_1,train_dataset_2))

def crop_mixing(train_dataset_1,train_dataset_2):
  (image_1,label_1),(image_2,label_2) = train_dataset_1,train_dataset_2

  LAMBDA = tfp.distributions.Beta(0.2,0.2).sample(1)[0]

  r_x,r_y,r_w,r_h = box(LAMBDA)

  crop_1 = tf.image.crop_to_bounding_box(image_1,r_x,r_y,r_w,r_h)
  pad_1 = tf.image.pad_to_bounding_box(crop_1,r_x,r_y,IMG_SIZE,IMG_SIZE)

  crop_2 = tf.image.crop_to_bounding_box(image_2,r_x,r_y,r_w,r_h)
  pad_2 = tf.image.pad_to_bounding_box(crop_2,r_x,r_y,IMG_SIZE,IMG_SIZE)

  image = image_1-pad_1+pad_2

  #applying the cut-mix for labels too - to verify the situation well
  lamda = tf.cast(1- (r_w*r_h)/(IMG_SIZE*IMG_SIZE),dtype = tf.float32)
  label = lamda*tf.cast(label_1,dtype = tf.float32) + (1-lamda)*tf.cast(label_2,dtype = tf.float32)

  return image,label

#using the factor to apply mix-up data augmentation on images, labels - delivering a new  mixed
def mixup_augmentation(train_dataset_1,train_dataset_2):
  (image_1,label_1),(image_2,label_2) = train_dataset_1,train_dataset_2

  factor = tfp.distributions.Beta(0.2,0.4)

  # Sample a value from the Beta distribution
  sampled_factor = factor.sample(1)[0]

  # Use the sampled value for calculations
  image = sampled_factor * image_1 + (1 - sampled_factor) * image_2  #for images
  label = sampled_factor * tf.cast(label_1,dtype = tf.float32) + (1 - sampled_factor) * tf.cast(label_2,dtype = tf.float32)

  return image,label

BATCH_SIZE = 32

#defining the albumentations training pipeline -
augmentation_pipeline = A.Compose([
    A.Resize(IMG_SIZE,IMG_SIZE),
    A.OneOf([
        A.HorizontalFlip(),
        A.VerticalFlip()
    ],p = 0.3),
    A.RandomRotate90(),
    A.RandomBrightnessContrast(brightness_limit = 0.3,
                               contrast_limit = 0.3,
                               always_apply = False, p =0.4),
])

def alb_processing(image,label):
  aug_img = tf.numpy_function(func = augmentation_pipeline,inp = [image],Tout = tf.float32)
  return aug_img,label

def aug_albumentation(iamge):
  data = {"image":image}
  image = augmentation_pipeline(**data)
  image = image['image']
  image = tf.cast(image/255,dtype = tf.float32) #scaling the images

  return image

#defining the new mixed training data -
training_data = (
    mixed_dataset
    .shuffle(buffer_size=8,reshuffle_each_iteration=True)
    .map(crop_mixing)
    .batch(BATCH_SIZE)
    .prefetch(tf.data.AUTOTUNE)
)

original_image,label = next(iter(train))
image_data = original_image[0].numpy()
image_data = np.clip(image_data, 0,1)
normalized_image = ((image_data - np.min(image_data))/np.max(image_data)-np.min(image_data))
plt.imshow(normalized_image)
plt.show()

def define_output(x):
  if x>0.5:
    print('Unaffected')
  else:
    print('paracitized')

plt.figure(figsize = (15,15))
for i in range(1,32):
  plt.subplot(8,4,i)
  plt.imshow(original_image[i].numpy().astype('uint8'))
  plt.axis('off')

BATCH_SIZE = 32

train = train.map(augment).shuffle(buffer_size = 8,reshuffle_each_iteration = True).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE) #the training data is already augmentede - so no need...
val = val.shuffle(buffer_size = 8,reshuffle_each_iteration = True).map(resize_rescale).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)

normalizer = Normalization()

from matplotlib import pyplot as plt

"""<h1><b><u>Building Custom Loss Functions</u></b></h1><br>
<p>
This would be by inheriting the Loss class and creating new losses within a child class
</p>
"""

FACTOR = 0.3

def custom_bce(FACTOR):
  def custom_loss(y_true,y_pred):
    bce = BinarCrossEntropy()
    return bce(y_true,y_pred)*FACTOR
    return custom_loss

class CustomBCE(Loss):
  def __init__(FACTOR):
    super(CustomBCE,self).__init__()
    self.FACTOR = FACTOR
  def call(self,y_true,y_pred):
    bce = BinaryCrossEntropy() #we first of all need to instantiate
    return bce(y_true,y_pred)*self.FACTOR

"""<h1><b><U>Building custom callbacks</u></b></h1>

"""

class LossCallback(Callback):
  def on_epoch_end(self,epoch, logs):
    return f"\n Epoch -{epoch+1} has loss of {logs['loss']}"
  def on_batch_end(self,batch,logs):
    return f"\n Batch {batch + 1} has a loss of {logs['loss']}"

csv_callback = CSVLogger(
    filename = 'training.csv',
    separator = ",",
    append = False
)

#defining the early stopping callback -
es_callback = EarlyStopping(
    monitor = "precision",
    mode = "auto",
    patience = 2,
    restore_best_weights = True
)

test_dataset = test.batch(1)

class LogsImagesCallback(Callback):
  def on_epoch_end(self,epoch,logs):
    labels = []
    inp = []

    for x,y in test_dataset.as_numpy_iterator():
      x = tf.image.resize(x, [IMG_SIZE,IMG_SIZE])
      labels.append(y)
      inp.append(x)
    labels = np.array([i[0] for i in labels])
    predicted = lenet_new.predict(np.array(inp)[:,0,...])

    threshold = 0.5
    cm = confusion_matrix(labels, predicted>threshold)
    plt.figure(figsize = (8,8))

    sns.heatmap(cm, annot = True)
    plt.title("Malaria Predition Confusion Matrix")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.axis('off')

    buffer = io.BytesIO()
    plt.savefig(buffer,format = 'png')

    image = tf.image.decode_png(buffer.getvalue(),channels = 3)
    CURRENT_TIME = datetime.datetime.now().strftime('%d%m%y-%h%m%s')
    IMG_DIR = './logs'+CURRENT_TIME+'./images'
    image_writer = tf.summary.create_file_writer(IMG_DIR)

    with image_writer.as_default():
      tf.summary.image('Training_matrix',image,epoch)

import os

tb_path = os.path.join("logd")

if not os.path.exists(tb_path):
  os.mkdir(tb_path)

tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir = "logs", profile_batch="100,132")

"""<h1><b><u>Defining custom Metrics</u></b></h1>"""

#building a custom metric class -
class CustomAccuracy(tf.keras.metrics.Metric):
  def __init__(self,name = "custom_accuracy",FACTOR = 1):
    super(CustomAccuracy,self).__init__()
    self.FACTOR = FACTOR #initializing the differentiating paramter
    self.accuracy = self.add_weight(name = name, initializer = "zeros") #adding the accuracy metric
    self.binary_accuracy= BinaryAccuracy() #this is the instantiation of the object in the main Metric class of Tensorflow

  def update_state(self,y_true,y_pred, sample_weight = None):
    self.binary_accuracy.update_state(tf.cast(y_true,dtype = tf.float32),y_pred)
    result = self.binary_accuracy.result()*self.FACTOR #being a class object, it's result can only be manipulated, not the class and its instance methods
    self.accuracy.assign(result)

  def result(self):
    return self.accuracy #returns the result each epoch/iteration

  def reset_state(self): #this is to reset the metric at the start of each epoch
    self.accuracy.assign(0)
    self.binary_accuracy.reset_state()

#here, we can modify the function within a custom-defined function
def cutom_accuracy(y_true, y_pred):
  return BinaryAccuracy(y_true,y_pred)

def cutom_metric(FACTOR):
  def metric(y_true,y_pred):
    return BinaryAccuracy(y_true,y_pred)*FACTOR
  return metric #here we are returning a function itself.

"""<h2><b><u> Functional API Model </h2></b></u>
<p>
The functional API allows arbitrary (dynamic) model architectures by broadly allowing stacking up the layers in any order desired and hence transforming the data accordingly. As opposed to the Seuquential API where the model has to adhere to a certain order of layers and training execution
</p>
"""

dropout_rate = 0.2

feature_extractor = tf.keras.Sequential([
                      normalizer,
                      # augmentation_layer,
                      Conv2D(filters = 6, kernel_size = 3, activation = "relu", padding = "same", strides = 1, kernel_regularizer = L2(0.02)),
                      BatchNormalization(),
                      MaxPool2D(pool_size = 2, strides = 2),
                      Dropout(dropout_rate),
                      Conv2D(filters = 6, kernel_size = 3, activation = "relu", padding = "same", strides = 1, kernel_regularizer = L2(0.02)),
                      BatchNormalization(),
                      MaxPool2D(pool_size = 2, strides = 2),
                      Dropout(dropout_rate),
                      Conv2D(filters = 6, kernel_size = 3,activation = "relu", padding = "same", strides = 1, kernel_regularizer = L2(0.02)),
                      BatchNormalization(),
                      MaxPool2D(pool_size = 2, strides = 2),
                      Dropout(dropout_rate),
                      ])
# feature_extractor.summary()

"""<h1><b><u>Re-structuring the model with hyperparameter tuning</h1></b></u>"""

def model_tune(hparams):
  feature_extractor = tf.keras.Sequential([
                      Input(shape = (224,224,3)),
                      normalizer,
                      # augmentation_layer,
                      Conv2D(filters = 6, kernel_size = 3, activation = "relu", padding = "same", strides = 1, kernel_regularizer = L2(hparams['L2_LR'])),
                      BatchNormalization(),
                      MaxPool2D(pool_size = 2, strides = 2),
                      Dropout(hparams['HP_DROPOUT']),
                      Conv2D(filters = 6, kernel_size = 3, activation = "relu", padding = "same", strides = 1, kernel_regularizer = L2(hparams['L2_LR'])),
                      BatchNormalization(),
                      MaxPool2D(pool_size = 2, strides = 2),
                      Dropout(hparams['HP_DROPOUT']),
                      Conv2D(filters = 6, kernel_size = 3,activation = "relu", padding = "same", strides = 1, kernel_regularizer = L2(hparams['L2_LR'])),
                      BatchNormalization(),
                      MaxPool2D(pool_size = 2, strides = 2),
                      Dropout(hparams['HP_DROPOUT']),
                      Flatten(),
                      Dense(hparams['NUM_UNITS_1'], activation = "tanh"),
                      BatchNormalization(),
                      Dense(1, activation = "sigmoid"),
                      BatchNormalization(),
                      ])

  feature_extractor.compile(
    optimizer = tf.keras.optimizers.Adam(learning_rate = hparams['OPT_LR']),
    loss = tf.keras.losses.BinaryFocalCrossentropy(),
    metrics = metrics,
    run_eagerly = True
)

  feature_extractor.fit(val,epochs = 1)
  eval_results = feature_extractor.evaluate(val)
  eval_loss = eval_results[0]
  accuracy = eval_results[1]

  return accuracy

#defining the range of values for hyper parameters -
"""
This is hyper-parameter tuning via grid search, where the parameter values are being taken from a grid, i.e. a list of pre-defined values.
This works well with a shorter training bacth and a small model
However, with increase in data this could be computatinooally problematic - so, random search is also used in such a case
Theu
"""
L2_LR = hp.HParam('l2_lr', hp.Discrete([1e-4,1e-3]))
HP_DROPOUT = hp.HParam('hp_dropout', hp.Discrete([0.1,0.2,0.3]))
NUM_UNITS_1 = hp.HParam('num_units_1', hp.Discrete([16,32,64,128]))
OPT_LR = hp.HParam('opt_lr', hp.Discrete([0.01,0.001]))

!pip install -U tensorboard_plugin_profile

metrics = [BinaryAccuracy(name = "binary_accuracy"), FalseNegatives(name = "false_negatives"), FalsePositives(name = "false_positives"),TruePositives(name = "true_positives"), TrueNegatives(name = "true_negatives"), Precision(name = 'precision'), Recall(name = "recall"), AUC(name = "auc")]

run_count = 0
for num_units_1 in NUM_UNITS_1.domain.values:
  for hp_dropout in HP_DROPOUT.domain.values:
    for l2_lr in L2_LR.domain.values:
      for opt_lr in OPT_LR.domain.values:

        hparams = {
            'NUM_UNITS_1':num_units_1,
            'HP_DROPOUT':hp_dropout,
            'L2_LR':l2_lr,
            'OPT_LR':opt_lr
        }

        file_writer = tf.summary.create_file_writer('logs/'+str(run_count))
        run_count+=1

        with file_writer.as_default():
          hp.hparams(hparams)
          accuracy = model_tune(hparams)
          tf.summary.scalar('accuracy',accuracy,run_count)

model_input = Input(shape = (224,224,3))

#the functional API enables a better layer-by-layer understanding of how data flow works in a network
x = feature_extractor(model_input)
x = Flatten()(x)
x = Dense(250, activation = "tanh")(x)
x = BatchNormalization()(x)
x = Dense(200, activation = "tanh")(x)
x = BatchNormalization()(x)
model_output = Dense(1, activation = "sigmoid")(x)

lenet_new = Model(inputs = model_input, outputs = model_output)
lenet_new.summary()

"""<h2><b><u>Model Sub-classing</u></b></h2>"""

class FeatureExtractor(Layer): #model created as a child class of the keras "Layer" class
  def __init__(self, filters, strides, activation, padding, pool_size, kernel_size):
    super(FeatureExtractor,self).__init__()

    # Corrected the order of arguments to Conv2D
    self.conv_1 = Conv2D(filters, kernel_size, strides=strides, activation=activation, padding=padding)
    self.batch_normalizer_1 = BatchNormalization()
    self.pool_1 = MaxPool2D(pool_size, strides=strides)

    self.conv_2 = Conv2D(filters, kernel_size, strides=strides, activation=activation, padding=padding)
    self.batch_normalizer_2 = BatchNormalization()
    self.pool_2 = MaxPool2D(pool_size, strides)

    self.conv_3 = Conv2D(filters, kernel_size, strides=strides, activation=activation, padding=padding)
    self.batch_normalizer_3 = BatchNormalization()
    self.pool_3 = MaxPool2D(pool_size, strides)

  @tf.function
  def call(self, x):
    x = self.conv_1(x)
    x = self.batch_normalizer_1(x)
    x = self.pool_1(x)
    x = self.conv_2(x)
    x = self.batch_normalizer_2(x)
    x = self.pool_2(x)
    x = self.conv_3(x)
    x = self.batch_normalizer_3(x)
    x = self.pool_3(x)

    return x

feature_subclassed = FeatureExtractor(filters = 6, strides = (2,2), activation = 'relu', padding = 'valid', pool_size = 2, kernel_size = 3)

#creating a custom layer - these can be used in our model normally as we add any other layer: either via sequential or functional API
class Neural_learn:
  def __init__(self, output_units):
    super(Neural_learn, self).__init__()
    self.output_units = output_units

    def build(self,input_features_shape):
      self.weights = self.add_weight(shape = (input_features_shape[-1],self.output_units),initializer = 'random_normal', trainable = True)
      self.biases = self.add_weights((output_units,),initializer = 'random_normal',  trainable = True)

    def call(self, input_features):

      pre_output = tf.matmul(input_features, self.weights)+self.biases

      if activation =='relu':
        return tf.nn.relu(pre_output)
      elif activation == 'sigmoid':
        return tf.math.sigmoid(pre_output)
      else:
        return pre_output

lenet_new = tf.keras.Sequential([
                      Input(shape = (224,224,3)),
                      normalizer,
                      # augmentation_layer,
                      Conv2D(filters = 6, kernel_size = 3, activation = "relu", padding = "same", strides = 1, kernel_regularizer = L2(hparams['L2_LR'])),
                      BatchNormalization(),
                      MaxPool2D(pool_size = 2, strides = 2),
                      Dropout(hparams['HP_DROPOUT']),
                      Conv2D(filters = 6, kernel_size = 3, activation = "relu", padding = "same", strides = 1, kernel_regularizer = L2(hparams['L2_LR'])),
                      BatchNormalization(),
                      MaxPool2D(pool_size = 2, strides = 2),
                      Dropout(hparams['HP_DROPOUT']),
                      Conv2D(filters = 6, kernel_size = 3,activation = "relu", padding = "same", strides = 1, kernel_regularizer = L2(hparams['L2_LR'])),
                      BatchNormalization(),
                      MaxPool2D(pool_size = 2, strides = 2),
                      Dropout(hparams['HP_DROPOUT']),
                      Flatten(),
                      Dense(hparams['NUM_UNITS_1'], activation = "tanh"),
                      BatchNormalization(),
                      Dense(1, activation = "sigmoid"),
                      BatchNormalization(),
                      ])

lenet_new.compile(
    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01),
    loss = tf.keras.losses.BinaryFocalCrossentropy(),
    metrics = metrics,
    run_eagerly = True
)

CUSTOM_TRAIN = os.path.join('logs','custom','custom_train')
CUSTOM_VAL = os.path.join('logs','custom','custom_val')
train_logger = tf.summary.create_file_writer(CUSTOM_TRAIN)
val_logger = tf.summary.create_file_writer(CUSTOM_VAL)

#ddefining the learning rate scheduler -
def lr_scheduler(epoch,lr):
  if epoch<=1:
    learning_rate = lr
  else:
    learning_rate = lr*tf.math.exp(0.1)
    learning_rate = learning_rate.numpy()
  with train_logger.as_default():
    tf.summary.scalar("Learning_rate",learning_rate,epoch)
  return learning_rate
learning_rate_scheduler = LearningRateScheduler(lr_scheduler, verbose = 1)

checkpoints = ModelCheckpoint(
    filepath = "malaria_model.keras",
    monitor = 'val_loss',
    save_best_only = False,
    save_weights_only = False,
    mode = 'auto',
    save_freq = 'epoch',
    verbose = 1
)

history_funcnal = lenet_new.fit(train, epochs = 3, validation_data = val, callbacks = [tensorboard_callback,LogsImagesCallback()])

"""<h2><u><b>Creating Custom Fit function from scratch</h2></u></b>


"""

OPTIMIZER = Adam(learning_rate = 0.1)
EPOCHS = 3
LOSS = BinaryCrossentropy()
METRIC_VAL = CustomAccuracy()
METRIC = CustomAccuracy()

def training_block(x_batch,y_batch):
    with tf.GradientTape() as recorder:
      y_pred = lenet_new(x_batch, training = True)
      loss =  LOSS(y_batch,y_pred)

    partial_derivative = recorder.gradient(loss,lenet_new.trainable_weights)
    OPTIMIZER.apply_gradients(zip(partial_derivative,lenet_new.trainable_weights))
    METRIC.update_state(y_batch,y_pred)

    return loss

def validation_block(x_batch_val,y_batch_val):
    y_pred_val = lenet_new(x_batch_val,training = False)
    loss_val = LOSS(y_batch_val,y_pred_val)
    METRIC_VAL.update_state(y_batch_val,y_pred_val)
    METRIC_VAL.reset_state()

    return loss_val

for epoch in range(EPOCHS):
  print(f"Training at epoch - {epoch}")
  for step,(x_batch,y_batch) in enumerate(training_data):
    training_loss = training_block(x_batch,y_batch)

  print(f"loss - {training_loss}")
  with train_logger.as_default():
    tf.summary.scalar("training_loss",training_loss,epoch)
  with train_logger.as_default():
    tf.summary.scalar("training_accuracy", METRIC.result(),epoch)
  METRIC.reset_state()

    #extending it onto the validation dataset too -
  for (x_batch_val,y_batch_val) in val:
    validation_loss = validation_block(x_batch_val,y_batch_val)
    with val_logger.as_default():
      tf.summary.scalar("val_loss",validation_loss,epoch)
    with val_logger.as_default():
      tf.summary.scalar("val_accuracy",METRIC_VAL.result(),epoch)

  METRIC_VAL.reset_state()

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir logs

plt.plot(history_funcnal.history['binary_accuracy'])
# plt.plot(history_funcnal.history[['_accuracy'])
plt.title('model accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
# plt.legend(['train','val'],loc = 'upper left')

plt.plot(history_funcnal.history['false_negatives'])
plt.plot(history_funcnal.history['false_positives'])
plt.plot(history_funcnal.history['true_negatives'])
plt.plot(history_funcnal.history['true_positives'])
plt.title('COMPARING LABEL CATEGORIES')
plt.xlabel('epochs')
plt.ylabel('label_category')
plt.legend(['false_negatives','false_positives,true_negatives,true_positives'], loc = 'upper left')

#getting done with the post -training processes for model evluation -
test = test.batch(1)

print(test)

lenet_new.evaluate(val)

label = np.concatenate([y for x,y in val.as_numpy_iterator()])

predictions = lenet_new.predict(val)



#defining the threshold value to classify the predictions as parasitic or non-parasitic
threshold = 0.5
cm = confusion_matrix(label, predictions>threshold)
print(cm)

sns.heatmap(cm, annot = True)
plt.title("Malaria Predition Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

#defining a roc (reciever-operating charecteristic curve)
fp,tp,thresholds = roc_curve(label, predictions)

len(fp), len(tp), len(thresholds)

plt.plot(fp,tp)
plt.title("ROC plot for Malaria Price prediction")
plt.xlabel("False Positives Rate")
plt.ylabel("True Positive Rate")
plt.grid()

#getting done with showing the thresholds -
skip = 100
for i in range(0, len(thresholds), skip):
  plt.text(fp[i],tp[i],thresholds[i])

plt.show()

"""<h2><b><u>Data_Preprocessing_and_model</u></b></h2>

"""

def visualize(original,augmented):
  plt.subplot(1,2,1)
  plt.imshow(original[0].numpy().astype('uint8'))
  plt.axis('off')
  plt.title('original image')
  plt.subplot(1,2,2)
  plt.imshow(augmented[0].numpy().astype('uint8'))
  plt.axis('off')
  plt.title('augmented image')

original_image, label = next(iter(train))

augmented = tf.image.adjust_saturation(original_image,0.3)

visualize(original_image, augmented)

